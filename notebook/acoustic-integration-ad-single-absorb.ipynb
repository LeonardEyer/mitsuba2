{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-05 18:41:17 INFO  main  [optix_api.cpp:56] Dynamic loading of the Optix library ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import enoki as ek\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mitsuba\n",
    "mitsuba.set_variant('gpu_autodiff_acoustic')\n",
    "from mitsuba.python.util import traverse\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def estimate_detector_radius(room_dimensions, N):\n",
    "    return ((15 * room_dimensions[0] * room_dimensions[1] * room_dimensions[2]) / (2 * np.pi * N))**(1/2)\n",
    "\n",
    "def estimate_max_depth(box_dimensions, max_time, boost=1):\n",
    "    max_box_distance = np.linalg.norm(box_dimensions) / 2\n",
    "    max_box_time = max_box_distance / 343\n",
    "    max_depth_estimate = np.ceil(max_time / max_box_time * boost).astype(int) \n",
    "    return max_depth_estimate\n",
    "\n",
    "def make_shoebox_scene(emitter_pos, sensor_pos, box_dimensions, radius, max_time, time_steps, \n",
    "                       spp, bins, rfilter, max_depth, samples_per_pass, scattering,absorption, hide_sensor=True):\n",
    "    \n",
    "    from mitsuba.core import ScalarTransform4f\n",
    "\n",
    "    def transform(scale=None, rotate=None, translate=None):\n",
    "        if translate is None:\n",
    "            translate = [0, 0, 0]\n",
    "        if scale is None:\n",
    "            scale = [1, 1, 1]\n",
    "        if rotate is None:\n",
    "            rotate = ([0, 0, 0], 0)\n",
    "\n",
    "        a = ScalarTransform4f.scale(scale)\n",
    "        b = ScalarTransform4f.rotate(*rotate)\n",
    "        c = ScalarTransform4f.translate(translate)\n",
    "        return c * b * a\n",
    "\n",
    "    global_translation = transform(translate=np.array(box_dimensions) / 2)\n",
    "\n",
    "    scene = {\n",
    "        \"type\": \"scene\",\n",
    "        \"bsdf_neutral\": {\n",
    "            \"type\": \"acousticbsdf\",\n",
    "            \"scattering\": {\n",
    "                \"type\": \"spectrum\",\n",
    "                \"value\": scattering\n",
    "            },\n",
    "            \"absorption\": {\n",
    "                \"type\": \"spectrum\",\n",
    "                \"value\": absorption\n",
    "            }\n",
    "        },\n",
    "        \"emitter_shape\": {\n",
    "            \"id\": \"emitter\",\n",
    "            \"type\": \"sphere\",\n",
    "            \"radius\": radius,\n",
    "            \"to_world\": transform(translate=emitter_pos),\n",
    "            \"emitter\": {\n",
    "                \"type\": \"area\",\n",
    "                \"radiance\": {\n",
    "                    \"type\": \"uniform\",\n",
    "                    \"value\": 1\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"sensor\": {\n",
    "            \"type\": \"microphone\",\n",
    "            \"to_world\": transform(translate=sensor_pos),\n",
    "            \"sampler\": {\n",
    "                \"type\": \"independent\",\n",
    "                \"sample_count\": spp\n",
    "            },\n",
    "            \"myfilm\": {\n",
    "                \"type\": \"tape\",\n",
    "                \"time_steps\": time_steps,\n",
    "                \"wav_bins\": len(bins),\n",
    "                \"rfilter\": rfilter\n",
    "            }  \n",
    "        },\n",
    "        \"shoebox\": {\n",
    "            \"id\": \"shoebox\",\n",
    "            \"type\": \"obj\",\n",
    "            \"filename\": \"../resources/cuberoom.obj\",\n",
    "            \"bsdf\": {\n",
    "                \"type\": \"ref\",\n",
    "                \"id\": \"bsdf_neutral\"\n",
    "            },\n",
    "            \"to_world\": global_translation * transform(scale=np.array(box_dimensions) / 2)\n",
    "        },\n",
    "        \"integrator\": {\n",
    "            \"type\": \"acousticpath\",\n",
    "            \"max_depth\": int(max_depth),\n",
    "            \"max_time\": max_time,\n",
    "            \"wavelength_bins\": ','.join(str(x) for x in bins),\n",
    "            \"samples_per_pass\": samples_per_pass\n",
    "        }\n",
    "    }\n",
    "    return scene\n",
    "\n",
    "def get_vals(data, size, copy=False):\n",
    "    return np.array(data, copy=copy).reshape(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-05 18:41:43 INFO  main  [PluginManager] Loading plugin &quot;plugins/obj.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-05 18:41:43 INFO  main  [PluginManager] Loading plugin &quot;plugins/acousticpath.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-05 18:41:43 INFO  main  [Scene] Building scene in OptiX ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mitsuba.core.xml import load_string, load_dict\n",
    "\n",
    "bins = [1, 7, 17]\n",
    "absorption = list(zip(bins, [0.55, 0.08, 0.25]))\n",
    "\n",
    "config = {\n",
    "    \"bins\": bins,\n",
    "    \"absorption\": absorption,\n",
    "    \"scattering\": 0.1,\n",
    "    \"max_time\": 1,\n",
    "    \"time_steps\": 10,\n",
    "    \"spp\": 1000,\n",
    "    \"samples_per_pass\": 1000,\n",
    "    \"box_dimensions\": [25, 12, 7],\n",
    "    \"emitter_pos\": [20, 7, 2],\n",
    "    \"sensor_pos\": [9, 6, 1],\n",
    "    \"radius\": 1.,  #estimate_detector_radius(box_dimensions, spp)\n",
    "    \"max_depth\": 132, #estimate_max_depth(0.9),\n",
    "    \"rfilter\": {\n",
    "        \"type\": \"gaussian\",\n",
    "        \"stddev\": 0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "scene_dict = make_shoebox_scene(**config)\n",
    "scene = load_dict(scene_dict)\n",
    "size = scene.sensors()[0].film().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55, 0.08, 0.25]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'mitsuba.render.TimeDependentIntegrator' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-14a3ea1f227b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmitsuba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautodiff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhist_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitsuba2-acoustic/build/dist/python/mitsuba/python/autodiff.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(scene, spp, unbiased, optimizer, sensor_index, pre_render_callback)\u001b[0m\n\u001b[1;32m    201\u001b[0m                             'is either an integer or None!')\n\u001b[1;32m    202\u001b[0m         \u001b[0mpre_render_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_render_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msensor_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitsuba2-acoustic/build/dist/python/mitsuba/python/autodiff.py\u001b[0m in \u001b[0;36m_render_helper\u001b[0;34m(scene, spp, sensor_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maovs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mspec\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'mitsuba.render.TimeDependentIntegrator' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "from mitsuba.core import Spectrum, Float\n",
    "\n",
    "diff_param = 'AcousticBSDF.absorption.values'\n",
    "\n",
    "params = traverse(scene)\n",
    "print(params[diff_param])\n",
    "params.keep([diff_param])\n",
    "param_ref = Spectrum(params[diff_param])\n",
    "\n",
    "from mitsuba.python.autodiff import render\n",
    "hist_ref = render(scene, spp=None)\n",
    "plt.plot(get_vals(hist_ref, size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "class OptimizationPlot:\n",
    "    def __init__(self, name, bins, target, max_time=1.0):\n",
    "        self._error = []\n",
    "        self._bins = bins\n",
    "        self._max_time = max_time\n",
    "        \n",
    "        X = np.linspace(0, len(self._bins), target.shape[1])\n",
    "        Y = np.linspace(0, self._max_time, target.shape[0])\n",
    "        X, Y = np.meshgrid(X, Y)\n",
    "    \n",
    "        self._fig = go.FigureWidget(make_subplots(rows=1, cols=2, subplot_titles=(\"Spectogram\", \"Error\"), specs=[[{\"type\": \"surface\"}, {\"type\": \"scatter\"}]]))\n",
    "        \n",
    "        self._fig.update_layout(title=name, scene_aspectmode='cube')\n",
    "\n",
    "        self._fig.add_surface(row=1, col=1, showscale=False, name=\"current\")\n",
    "        self._fig.add_surface(row=1, col=1, showscale=False, opacity=0.2, colorscale=['blue', 'blue'], name=\"target\")\n",
    "        self._fig.add_scatter(row=1, col=2)\n",
    "                \n",
    "        self._fig.data[0].x = X\n",
    "        self._fig.data[0].y = Y\n",
    "        self._fig.data[1].x = X\n",
    "        self._fig.data[1].y = Y\n",
    "        self._fig.data[1].z = target\n",
    "\n",
    "    def plot_optimization_state(self, current, err_ref):\n",
    "        self._error.append(err_ref)\n",
    "        self._fig.data[0].z = current\n",
    "\n",
    "        self._fig.data[2].y = self._error\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "\n",
    "    @property\n",
    "    def error(self):\n",
    "        return self._error\n",
    "    \n",
    "    def show(self):\n",
    "        return self._fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebae168be5164bd7a559e4afe84d2094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'current',\n",
       "              'scene': 'scene',\n",
       "              'showscale': Falâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = 100\n",
    "np_hist_ref = get_vals(hist_ref, size, copy=True)\n",
    "\n",
    "def mse(a, b):\n",
    "    return ek.hsum(ek.sqr(a - b)) / len(hist)\n",
    "\n",
    "def mse_decay(a, b):\n",
    "    return ek.hsum(ek.sqr(a - b) * ek.exp(-Float.linspace(0, 5, len(hist)))) / len(hist)\n",
    "\n",
    "err_func = mse\n",
    "params[diff_param] = [0.1] * len(bins)\n",
    "\n",
    "# Construct an optimizer that will adjust the parameters 'params'\n",
    "from mitsuba.python.autodiff import Adam, SGD\n",
    "opt = SGD(params, lr=.2)\n",
    "\n",
    "opt_plot = OptimizationPlot(err_func.__name__, config['bins'], np_hist_ref, config['max_time'])\n",
    "opt_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934b8496d6a4497ab9c15ae3b18affb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='iterations'), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-76bdc96d0d64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Perform a differentiable rendering of the scene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnp_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitsuba2/cmake-build-remote/dist/python/mitsuba/python/autodiff.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(scene, spp, unbiased, optimizer, sensor_index)\u001b[0m\n\u001b[1;32m    250\u001b[0m             raise Exception('render(): unbiased=False requires that spp '\n\u001b[1;32m    251\u001b[0m                             'is either an integer or None!')\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msensor_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msensor_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitsuba2/cmake-build-remote/dist/python/mitsuba/python/autodiff.py\u001b[0m in \u001b[0;36m_render_helper_time_dependent\u001b[0;34m(scene, spp, sensor_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mintegrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_acoustic_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(iterations), desc='iterations')\n",
    "\n",
    "for it in pbar:\n",
    "    # Perform a differentiable rendering of the scene\n",
    "    hist = render(scene, optimizer=opt, unbiased=False, spp=None)\n",
    "\n",
    "    np_hist = get_vals(hist, size, copy=True)\n",
    "\n",
    "    # Objective: MSE between 'hist' and 'hist_ref'\n",
    "    ob_val = err_func(hist, hist_ref)\n",
    "\n",
    "    # Back-propagate errors to input parameters\n",
    "    ek.backward(ob_val)\n",
    "\n",
    "    # Optimizer: take a gradient step\n",
    "    opt.step()\n",
    "\n",
    "    # Compute error\n",
    "    err_ref = np.sum(np.square(param_ref - params[diff_param]))\n",
    "    \n",
    "    pbar.set_postfix({'absorption': params[diff_param]})\n",
    "\n",
    "    # Plot progress\n",
    "    opt_plot.plot_optimization_state(np_hist, err_ref)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
