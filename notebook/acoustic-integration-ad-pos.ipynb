{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:15 INFO  main  [optix_api.cpp:56] Dynamic loading of the Optix library ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mitsuba\n",
    "mitsuba.set_variant('gpu_autodiff_acoustic')\n",
    "from mitsuba.python.util import traverse\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from mitsuba.core import xml, Thread, Transform4f, Bitmap, Float, Vector3f, UInt32\n",
    "from mitsuba.python.autodiff import render, write_bitmap, Adam, SGD\n",
    "import enoki as ek\n",
    "ek.cuda_set_log_level(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def estimate_detector_radius(room_dimensions, N):\n",
    "    return ((15 * room_dimensions[0] * room_dimensions[1] * room_dimensions[2]) / (2 * np.pi * N))**(1/2)\n",
    "\n",
    "def estimate_max_depth(box_dimensions, max_time, boost=1):\n",
    "    max_box_distance = np.linalg.norm(box_dimensions) / 2\n",
    "    max_box_time = max_box_distance / 343\n",
    "    max_depth_estimate = np.ceil(max_time / max_box_time * boost).astype(int) \n",
    "    return max_depth_estimate\n",
    "\n",
    "def make_shoebox_scene(emitter_pos, sensor_pos, box_dimensions, radius, max_time, time_steps, \n",
    "                       spp, bins, rfilter, max_depth, samples_per_pass, scattering,absorption, hide_sensor=True):\n",
    "    \n",
    "    from mitsuba.core import ScalarTransform4f\n",
    "\n",
    "    def transform(scale=None, rotate=None, translate=None):\n",
    "        if translate is None:\n",
    "            translate = [0, 0, 0]\n",
    "        if scale is None:\n",
    "            scale = [1, 1, 1]\n",
    "        if rotate is None:\n",
    "            rotate = ([0, 0, 0], 0)\n",
    "\n",
    "        a = ScalarTransform4f.scale(scale)\n",
    "        b = ScalarTransform4f.rotate(*rotate)\n",
    "        c = ScalarTransform4f.translate(translate)\n",
    "        return c * b * a\n",
    "\n",
    "    global_translation = transform(translate=np.array(box_dimensions) / 2)\n",
    "\n",
    "    scene = {\n",
    "        \"type\": \"scene\",\n",
    "        \"bsdf_neutral\": {\n",
    "            \"type\": \"acousticbsdf\",\n",
    "            \"scattering\": {\n",
    "                \"type\": \"spectrum\",\n",
    "                \"value\": scattering\n",
    "            },\n",
    "            \"absorption\": {\n",
    "                \"type\": \"spectrum\",\n",
    "                \"value\": absorption\n",
    "            }\n",
    "        },\n",
    "        \"emitter_shape\": {\n",
    "            \"id\": \"emitter\",\n",
    "            \"type\": \"sphere\",\n",
    "            \"radius\": radius,\n",
    "            \"to_world\": transform(translate=emitter_pos),\n",
    "            \"emitter\": {\n",
    "                \"type\": \"smoothsphere\",\n",
    "                \"radiance\": {\n",
    "                    \"type\": \"uniform\",\n",
    "                    \"value\": 1\n",
    "                },\n",
    "                \"blur_size\": 0.5\n",
    "            }\n",
    "        },\n",
    "        \"sensor\": {\n",
    "            \"type\": \"microphone\",\n",
    "            \"to_world\": transform(translate=sensor_pos),\n",
    "            \"sampler\": {\n",
    "                \"type\": \"independent\",\n",
    "                \"sample_count\": spp\n",
    "            },\n",
    "            \"myfilm\": {\n",
    "                \"type\": \"tape\",\n",
    "                \"time_steps\": time_steps,\n",
    "                \"wav_bins\": len(bins),\n",
    "                \"rfilter\": rfilter\n",
    "            }  \n",
    "        },\n",
    "        \"shoebox\": {\n",
    "            \"id\": \"shoebox\",\n",
    "            \"type\": \"obj\",\n",
    "            \"filename\": \"../resources/cuberoom.obj\",\n",
    "            \"bsdf\": {\n",
    "                \"type\": \"ref\",\n",
    "                \"id\": \"bsdf_neutral\"\n",
    "            },\n",
    "            \"to_world\": transform(scale=np.array(box_dimensions))\n",
    "        },\n",
    "        \"integrator\": {\n",
    "            \"type\": \"acousticpathreparam\",\n",
    "            \"max_depth\": int(max_depth),\n",
    "            \"max_time\": max_time,\n",
    "            \"wavelength_bins\": ','.join(str(x) for x in bins),\n",
    "            \"samples_per_pass\": samples_per_pass\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return scene\n",
    "\n",
    "def get_vals(data, size, copy=False):\n",
    "    return np.array(data, copy=copy).reshape(size)\n",
    "\n",
    "\n",
    "# Convert flat array into a vector of arrays (will be included in next enoki release)\n",
    "def ravel(buf, dim = 3):\n",
    "    idx = dim * UInt32.arange(ek.slices(buf) // dim)\n",
    "    return Vector3f(ek.gather(buf, idx), ek.gather(buf, idx + 1), ek.gather(buf, idx + 2))\n",
    "\n",
    "# Return contiguous flattened array (will be included in next enoki release)\n",
    "def unravel(source, target, dim = 3):\n",
    "    idx = UInt32.arange(ek.slices(source))\n",
    "    for i in range(dim):\n",
    "        ek.scatter(target, source[i], dim * idx + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/acousticbsdf.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/uniform.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/sphere.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/smoothsphere.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/d65.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/regular.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/diffuse.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/microphone.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/independent.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/tape.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/gaussian.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/obj.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [OBJMesh] Loading mesh from &quot;cuberoom.obj&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [OBJMesh] &quot;cuberoom.obj&quot;: read 12 faces, 24 vertices (912 B in 0ms)</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [PluginManager] Loading plugin &quot;plugins/acousticpathreparam.so&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [path-reparam-utils.h:37] Loading data from &quot;vmf-hemisphere.data&quot; ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [path-reparam-utils.h:101] Loaded VMFHemisphereIntegral data, 100x100.</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Changes of variables in light integrals using 4 samples</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Changes of variables in BSDFs integrals using 4 samples</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Changes of variables in pixel integrals using 4 samples</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Changes of variables using convolution if roughness &gt; 0.150000</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Convolutions using kernel with kappa = 1000.000000</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Variance reduction enabled</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Convolutions enabled</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Convolutions for envmap enabled</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Gradient of diffuse reflections enabled</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Disable gradients after bounce 1000</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #bbb\">2021-06-10 10:44:18 DEBUG main  [AcousticPathReparamIntegrator] Reusing camera samples is enabled</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace; color: #000\">2021-06-10 10:44:18 INFO  main  [Scene] Building scene in OptiX ..</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mitsuba.core.xml import load_string, load_dict\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"bins\": [1],\n",
    "    \"absorption\": 0.5,\n",
    "    \"scattering\": 1.0,\n",
    "    \"max_time\": 1,\n",
    "    \"time_steps\": 100,\n",
    "    \"spp\": 1,\n",
    "    \"samples_per_pass\": 1,\n",
    "    \"box_dimensions\": [1, 1, 1],\n",
    "    \"emitter_pos\": [1, 1, 1],\n",
    "    \"sensor_pos\": [-1, -1, -1],\n",
    "    \"radius\": .5,  \n",
    "    \"max_depth\": 50,\n",
    "    \"rfilter\": {\n",
    "        \"type\": \"gaussian\",\n",
    "        \"stddev\": 2.0\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "scene_dict = make_shoebox_scene(**config)\n",
    "scene = load_dict(scene_dict)\n",
    "size = scene.sensors()[0].film().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mitsuba.core import Spectrum, Float\n",
    "\n",
    "params = traverse(scene)\n",
    "positions_buf = params['shoebox.vertex_positions_buf']\n",
    "positions_initial = ravel(positions_buf)\n",
    "\n",
    "# Create differential parameter to be optimized\n",
    "scale_ref = Vector3f(5., 5, 5)\n",
    "\n",
    "# Create a new ParameterMap (or dict)\n",
    "params_optim = {\n",
    "    \"scale\" : scale_ref,\n",
    "}\n",
    "\n",
    "# Construct an Adam optimizer that will adjust the translation parameters\n",
    "opt = Adam(params_optim, lr=0.02)\n",
    "\n",
    "# Apply the transformation to mesh vertex position and update scene (e.g. Optix BVH)\n",
    "def apply_transformation():\n",
    "    trasfo = Transform4f.scale(params_optim[\"scale\"])\n",
    "    new_positions = trasfo.transform_point(positions_initial)\n",
    "    unravel(new_positions, params['shoebox.vertex_positions_buf'])\n",
    "    params.set_dirty('shoebox.vertex_positions_buf')\n",
    "    params.update()\n",
    "\n",
    "# Render a reference image (no derivatives used yet)\n",
    "apply_transformation()\n",
    "hist_ref = render(scene, spp=None)\n",
    "np_hist_ref = get_vals(hist_ref, size, copy=True)\n",
    "\n",
    "plt.plot(np_hist_ref)\n",
    "plt.show()\n",
    "print(np_hist_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "class OptimizationPlot:\n",
    "    def __init__(self, name, bins, target, max_time=1.0):\n",
    "        self._error = []\n",
    "        self._bins = bins\n",
    "        self._max_time = max_time\n",
    "        \n",
    "        T = np.linspace(0, self._max_time, target.shape[0])\n",
    "    \n",
    "        self._fig = go.FigureWidget(make_subplots(rows=1, cols=2, subplot_titles=(\"EDC\", \"Error\"), specs=[[{\"type\": \"scatter\"}, {\"type\": \"scatter\"}]]))\n",
    "\n",
    "        self._fig.add_scatter(row=1, col=1, name=\"current\")\n",
    "        self._fig.add_scatter(row=1, col=1, opacity=0.2, name=\"target\")\n",
    "        self._fig.add_scatter(row=1, col=2, name='error')\n",
    "                \n",
    "        self._fig.data[0].x = T\n",
    "        self._fig.data[0].y = [0] * target.shape[0]\n",
    "        self._fig.data[1].x = T\n",
    "        self._fig.data[1].y = target[:,0]\n",
    "\n",
    "    def plot_optimization_state(self, current, err_ref):\n",
    "        self._error.append(err_ref)\n",
    "        self._fig.data[0].y = current[:,0]\n",
    "\n",
    "        self._fig.data[2].y = self._error\n",
    "        \n",
    "        time.sleep(0.1)\n",
    "\n",
    "    @property\n",
    "    def error(self):\n",
    "        return self._error\n",
    "    \n",
    "    def show(self):\n",
    "        return self._fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07e55c97d0a4b8eaa953c1f05645baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'current',\n",
       "              'type': 'scatter',\n",
       "              'uid': '1621291â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iterations = 1000\n",
    "def mse(a, b):\n",
    "    return ek.hsum(ek.sqr(a - b)) / len(hist)\n",
    "\n",
    "# rescale object before starting the optimization process\n",
    "params_optim[\"scale\"] = Vector3f(10.0, 10.0, 10.0)\n",
    "\n",
    "opt_plot = OptimizationPlot(\"Optimize room scale\", config['bins'], np_hist_ref, config['max_time'])\n",
    "opt_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babf8065ed3a4a23a1893790878c0b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iterations:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda_malloc(): out of memory!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3a03628bf272>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Perform a differentiable rendering of the scene\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_render_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_transformation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnp_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitsuba2-acoustic/build/dist/python/mitsuba/python/autodiff.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(scene, spp, unbiased, optimizer, sensor_index, pre_render_callback)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mpre_render_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             image = _rh(scene, spp=spp[0],\n\u001b[0m\u001b[1;32m    256\u001b[0m                                    sensor_index=sensor_index)\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mitsuba2-acoustic/build/dist/python/mitsuba/python/autodiff.py\u001b[0m in \u001b[0;36m_render_helper_time_dependent\u001b[0;34m(scene, spp, sensor_index)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mintegrator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_acoustic_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda_malloc(): out of memory!"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(iterations), desc='iterations')\n",
    "\n",
    "for it in pbar:\n",
    "    # Perform a differentiable rendering of the scene\n",
    "    hist = render(scene, optimizer=opt, unbiased=True, spp=None, pre_render_callback=apply_transformation)\n",
    "\n",
    "    np_hist = get_vals(hist, size, copy=True)\n",
    "\n",
    "    # Objective: MSE between 'hist' and 'hist_ref'\n",
    "    ob_val = mse(hist, hist_ref)\n",
    "\n",
    "    # Back-propagate errors to input parameters\n",
    "    ek.backward(ob_val)\n",
    "\n",
    "    # Optimizer: take a gradient step\n",
    "    opt.step()\n",
    "\n",
    "    # Compute error\n",
    "    err_ref = np.sum(np.square(scale_ref - params_optim[\"scale\"]))\n",
    "    \n",
    "    pbar.set_postfix({'scale': params_optim[\"scale\"]})\n",
    "\n",
    "    # Plot progress\n",
    "    opt_plot.plot_optimization_state(np_hist, err_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ek.set_label(params_optim[\"scale\"], \"scale\")\n",
    "ek.set_label(ob_val, \"objective\")\n",
    "from graphviz import Source\n",
    "Source(ek.graphviz(ob_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ob_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist)\n",
    "plt.plot(hist_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_hist_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
